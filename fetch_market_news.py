"""
Step 1.5: ÏãúÏû• Îâ¥Ïä§ ÏàòÏßë
Jina Search & Reader APIÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏãúÏû• Î∞è Ï¢ÖÎ™© Îâ¥Ïä§ ÏàòÏßë
"""

import os
import json
import requests
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import re


class MarketNewsCollector:
    """Jina AIÎ•º ÏÇ¨Ïö©Ìïú ÏãúÏû• Îâ¥Ïä§ ÏàòÏßë ÌÅ¥ÎûòÏä§"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("JINA_API_KEY")
        if not self.api_key:
            raise ValueError("JINA_API_KEY not found in environment variables")

        self.search_url = "https://s.jina.ai/"
        self.reader_url = "https://r.jina.ai/"

    def parse_date_to_standard(self, date_str: str) -> str:
        """Îã§ÏñëÌïú ÎÇ†Ïßú ÌòïÏãùÏùÑ ÌëúÏ§Ä ÌòïÏãù(YYYY-MM-DD HH:MM:SS)ÏúºÎ°ú Î≥ÄÌôò"""
        if not date_str or date_str == 'unknown':
            return '1900-01-01 00:00:00'

        try:
            now = datetime.now()

            # ÏÉÅÎåÄ ÏãúÍ∞Ñ Ï≤òÎ¶¨: "4 hours ago", "1 day ago"
            if 'ago' in date_str.lower():
                numbers = re.findall(r'\d+', date_str)
                if not numbers:
                    return now.strftime('%Y-%m-%d %H:%M:%S')

                value = int(numbers[0])
                if 'hour' in date_str.lower():
                    target_date = now - timedelta(hours=value)
                elif 'day' in date_str.lower():
                    target_date = now - timedelta(days=value)
                elif 'week' in date_str.lower():
                    target_date = now - timedelta(weeks=value)
                elif 'month' in date_str.lower():
                    target_date = now - timedelta(days=value * 30)
                else:
                    target_date = now
                return target_date.strftime('%Y-%m-%d %H:%M:%S')

            # ISO 8601 ÌòïÏãù: "2025-10-01T08:19:28+00:00"
            if 'T' in date_str:
                date_part = date_str.split('+')[0].split('-')[0:3]
                date_part = '-'.join(date_part[:3])
                if len(date_part.split('T')) > 1:
                    parsed_date = datetime.strptime(date_part, '%Y-%m-%dT%H:%M:%S')
                else:
                    parsed_date = datetime.strptime(date_part, '%Y-%m-%d')
                return parsed_date.strftime('%Y-%m-%d %H:%M:%S')

            # ÏùºÎ∞ò ÌòïÏãù: "May 31, 2025" ÎòêÎäî "2025-05-31"
            if ',' in date_str:
                parsed_date = datetime.strptime(date_str.strip(), '%b %d, %Y')
            elif '-' in date_str and len(date_str) == 10:
                parsed_date = datetime.strptime(date_str, '%Y-%m-%d')
            else:
                return now.strftime('%Y-%m-%d %H:%M:%S')

            return parsed_date.strftime('%Y-%m-%d %H:%M:%S')

        except Exception as e:
            print(f"‚ö†Ô∏è Date parsing error for '{date_str}': {e}")
            return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    def search(self, query: str, max_results: int = 5, cutoff_date: Optional[str] = None) -> List[str]:
        """Jina Search APIÎ°ú Í≤ÄÏÉâ ÏàòÌñâ"""
        url = f'{self.search_url}?q={query}&n={max_results}'
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Accept': 'application/json',
            'X-Respond-With': 'no-content'
        }

        try:
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            data = response.json()

            filtered_urls = []
            for item in data.get('data', []):
                raw_date = item.get('date', 'unknown')
                standardized_date = self.parse_date_to_standard(raw_date)

                # ÎÇ†Ïßú ÌïÑÌÑ∞ÎßÅ (cutoff_date Ïù¥Ï†Ñ Ï†ïÎ≥¥Îßå)
                if cutoff_date and standardized_date > cutoff_date:
                    continue

                filtered_urls.append({
                    'url': item.get('url'),
                    'title': item.get('title', 'No title'),
                    'description': item.get('description', ''),
                    'date': standardized_date
                })

            print(f"  Found {len(filtered_urls)} results for '{query}'")
            return filtered_urls

        except Exception as e:
            print(f"‚ö†Ô∏è Search error for '{query}': {e}")
            return []

    def read_url(self, url: str) -> Optional[Dict]:
        """Jina Reader APIÎ°ú URL Ïª®ÌÖêÏ∏† Ïä§ÌÅ¨ÎûòÌïë"""
        reader_url = f'{self.reader_url}{url}'
        headers = {
            'Accept': 'application/json',
            'Authorization': f'Bearer {self.api_key}',
            'X-Timeout': '10',
            'X-With-Generated-Alt': 'true',
        }

        try:
            response = requests.get(reader_url, headers=headers, timeout=15)
            response.raise_for_status()
            data = response.json()

            content = data.get('data', {}).get('content', '')
            # Ïª®ÌÖêÏ∏† Í∏∏Ïù¥ Ï†úÌïú (Ï≤´ 2000Ïûê)
            if len(content) > 2000:
                content = content[:2000] + '...'

            return {
                'url': url,
                'title': data.get('data', {}).get('title', 'No title'),
                'description': data.get('data', {}).get('description', ''),
                'content': content,
                'publish_time': data.get('data', {}).get('publishedTime', 'unknown')
            }

        except Exception as e:
            print(f"‚ö†Ô∏è Reader error for '{url}': {e}")
            return None

    def collect_market_news(self, trading_date: str, symbols: List[str]) -> Dict:
        """ÏãúÏû• Îâ¥Ïä§ Î∞è Ï£ºÏöî Ï¢ÖÎ™© Îâ¥Ïä§ ÏàòÏßë"""
        print(f"\nüì∞ Collecting market news for {trading_date}...")

        # Í±∞ÎûòÏùº Í∏∞Ï§ÄÏúºÎ°ú cutoff (ÎØ∏Îûò Ï†ïÎ≥¥ Ï∞®Îã®)
        cutoff_datetime = f"{trading_date} 23:59:59"

        news_data = {
            'trading_date': trading_date,
            'collected_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'market_overview': [],
            'sector_news': [],
            'top_stocks_news': {}
        }

        # 1. Ï†ÑÏ≤¥ ÏãúÏû• Îâ¥Ïä§
        print("\n1Ô∏è‚É£ Collecting general market news...")
        market_queries = [
            "NASDAQ stock market news today",
            "US stock market outlook",
            "tech stocks market analysis"
        ]

        for query in market_queries:
            results = self.search(query, max_results=2, cutoff_date=cutoff_datetime)
            for result in results[:1]:  # Í∞Å ÏøºÎ¶¨Îãπ 1Í∞úÏî©Îßå
                article = self.read_url(result['url'])
                if article:
                    news_data['market_overview'].append(article)

        # 2. ÏÑπÌÑ∞ Îâ¥Ïä§
        print("\n2Ô∏è‚É£ Collecting sector news...")
        sector_queries = [
            "technology sector stocks",
            "semiconductor industry news"
        ]

        for query in sector_queries:
            results = self.search(query, max_results=2, cutoff_date=cutoff_datetime)
            for result in results[:1]:
                article = self.read_url(result['url'])
                if article:
                    news_data['sector_news'].append(article)

        # 3. Ï£ºÏöî Ï¢ÖÎ™© Îâ¥Ïä§ (ÏãúÍ∞ÄÏ¥ùÏï° ÏÉÅÏúÑ 10Í∞úÎßå)
        print("\n3Ô∏è‚É£ Collecting top stocks news...")
        top_symbols = symbols[:10]  # ÏÉÅÏúÑ 10Í∞úÎßå

        for symbol in top_symbols:
            print(f"  Searching for {symbol}...")
            results = self.search(f"{symbol} stock news", max_results=1, cutoff_date=cutoff_datetime)

            if results:
                article = self.read_url(results[0]['url'])
                if article:
                    news_data['top_stocks_news'][symbol] = [article]

        # ÌÜµÍ≥Ñ Ï∂úÎ†•
        print(f"\n‚úÖ News collection complete:")
        print(f"   - Market overview: {len(news_data['market_overview'])} articles")
        print(f"   - Sector news: {len(news_data['sector_news'])} articles")
        print(f"   - Stock news: {len(news_data['top_stocks_news'])} stocks")

        return news_data


def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    # Í±∞Îûò ÎÇ†Ïßú
    trading_date = os.getenv("TRADING_DATE")
    if not trading_date:
        trading_datetime = os.getenv("TRADING_DATETIME")
        if trading_datetime:
            trading_date = trading_datetime.split('T')[0] if 'T' in trading_datetime else trading_datetime.split()[0]
        else:
            now = datetime.now()
            if now.weekday() >= 5:  # Ï£ºÎßê
                print("‚ö†Ô∏è Weekend - No trading")
                return
            trading_date = now.strftime("%Y-%m-%d")

    print(f"üìÖ Trading Date: {trading_date}")

    # NASDAQ 100 Ïã¨Î≥º (prepare_trading_data.pyÏôÄ ÎèôÏùº)
    symbols = [
        "NVDA", "MSFT", "AAPL", "GOOG", "GOOGL", "AMZN", "META", "AVGO", "TSLA",
        "NFLX", "PLTR", "COST", "ASML", "AMD", "CSCO", "AZN", "TMUS", "MU", "LIN",
        "PEP", "SHOP", "APP", "INTU", "AMAT", "LRCX", "PDD", "QCOM", "ARM", "INTC",
        "BKNG", "AMGN", "TXN", "ISRG", "GILD", "KLAC", "PANW", "ADBE", "HON",
        "CRWD", "CEG", "ADI", "ADP", "DASH", "CMCSA", "VRTX", "MELI", "SBUX",
        "CDNS", "ORLY", "SNPS", "MSTR", "MDLZ", "ABNB", "MRVL", "CTAS", "TRI",
        "MAR", "MNST", "CSX", "ADSK", "PYPL", "FTNT", "AEP", "WDAY", "REGN", "ROP",
        "NXPI", "DDOG", "AXON", "ROST", "IDXX", "EA", "PCAR", "FAST", "EXC", "TTWO",
        "XEL", "ZS", "PAYX", "WBD", "BKR", "CPRT", "CCEP", "FANG", "TEAM", "CHTR",
        "KDP", "MCHP", "GEHC", "VRSK", "CTSH", "CSGP", "KHC", "ODFL", "DXCM", "TTD",
        "ON", "BIIB", "LULU", "CDW", "GFS"
    ]

    # Îâ¥Ïä§ ÏàòÏßë
    try:
        collector = MarketNewsCollector()
        news_data = collector.collect_market_news(trading_date, symbols)

        # JSON ÌååÏùºÎ°ú Ï†ÄÏû•
        output_file = Path("market_news.json")
        with open(output_file, "w", encoding='utf-8') as f:
            json.dump(news_data, f, indent=2, ensure_ascii=False)

        print(f"\n‚úÖ Market news saved to: {output_file}")

    except Exception as e:
        print(f"‚ùå Error collecting news: {e}")
        # ÏóêÎü¨ Ïãú Îπà Îâ¥Ïä§ ÌååÏùº ÏÉùÏÑ±
        empty_news = {
            'trading_date': trading_date,
            'collected_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'market_overview': [],
            'sector_news': [],
            'top_stocks_news': {},
            'error': str(e)
        }
        with open("market_news.json", "w", encoding='utf-8') as f:
            json.dump(empty_news, f, indent=2, ensure_ascii=False)
        print("‚ö†Ô∏è Created empty news file due to error")


if __name__ == "__main__":
    main()
